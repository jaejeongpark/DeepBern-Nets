TRAIN:
  EPOCHS: 10
  BATCH_SIZE: 512
  INIT_LR: 1e-3
  WEIGHT_DECAY: 0.001
  OPTIMIZER: AdamW
  LR_DECAY_RATE: 0.99
  LR_DECAY_START_EPOCH: 50
  LR_DECAY_METHOD: EXP
  DEVICE: cuda:1
  MODE: clean

# TEST:
#   BATCH_SIZE: 512
#   MODE: adv
#   IBP: True
#   BERN_IBP: True
#   PGD: True
#   DEVICE: cuda:1

ROBUSTNESS:
  ENABLE: False
  BOUNDING_METHOD: bern
  MIN_ALPHA: 0.0
  MAX_ALPHA: 1.0
  MIN_BETA: 0.0
  MAX_BETA: 0.0
  WARMUP_EPOCHS: 0
  ROBUST_TRAINING_START_EPOCH: 0
  ROBUST_TRAINING_LAST_EPOCH: 0
  EPS_START_EPOCH: 0
  EPS_LAST_EPOCH: 0
  MAX_EPS: 0.1
  MIN_EPS: 0.1
  TEST_EPS: 0.1
  TEST_EVERY_N_EPOCH : 20

MODEL:
  TYPE: CNNc
  HIDDEN_LAYERS: ""
  ACTIVATION: relu
  DEGREE: 2
  
DATASET: mnist

CHECKPOINT:
  DIR: experiments/mnist/
  LOAD: False
  PATH_TO_CKPT: ""

EXPERIMENT:
  NAME: mnist_CNNc_clean_epoch_timing
  RUN_NAME: mnist_CNNc_clean
  DESCRIPTION: "Training CNNa on MNIST dataset"


